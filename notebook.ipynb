{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF582 AXA Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load main librairies\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import datetime as dt\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import __version__\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "submission = pd.read_csv(\"data/submission.txt\", sep='\\t')\n",
    "\n",
    "\n",
    "iter_csv = pd.read_csv(\"data/train_2011_2012.csv\", sep=';',\n",
    "                            na_values=['A Définir', 'A DEFINIR', '9999-12-31 00:00:00.000'],\n",
    "                            usecols=['DATE','WEEK_END','DAY_WE_DS','TPER_TEAM','ASS_ASSIGNMENT','CSPL_RECEIVED_CALLS'],\n",
    "                           iterator=True, \n",
    "                           chunksize=1000)\n",
    "training_data = pd.concat([chunk[chunk['ASS_ASSIGNMENT'].isin(submission.ASS_ASSIGNMENT.unique())] for chunk in iter_csv])\n",
    "\n",
    "\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Aggregate the calls\n",
    "training_data = training_data.groupby([col for col in training_data.columns if not col == 'CSPL_RECEIVED_CALLS']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract the time slot from date\n",
    "def get_time(date):\n",
    "    time = dt.datetime.strptime(date,'%Y-%m-%d %H:%M:%S.000').time()\n",
    "    return time.hour * 3600 + time.minute * 60 + time.second\n",
    "\n",
    "def get_month(date):\n",
    "    month = dt.datetime.strptime(date,'%Y-%m-%d %H:%M:%S.000').month\n",
    "    return month\n",
    "\n",
    "epoch = dt.datetime.utcfromtimestamp(0)\n",
    "\n",
    "def unix_time_s(date_):\n",
    "    return (date_ - epoch).total_seconds()\n",
    "\n",
    "def get_tse(date):  #time since epoch\n",
    "    month = unix_time_s(dt.datetime.strptime(date,'%Y-%m-%d %H:%M:%S.000'))\n",
    "    return month\n",
    "\n",
    "#Join weather\n",
    "#training_data = pd.merge(training_data, meteo, how='left', on=['DATE'])\n",
    "\n",
    "#Deal with NAs. Would be better to replace with average\n",
    "#training_data.fillna(0,inplace = True)\n",
    "\n",
    "#Ca a l'air de fonctionner mais mieux vaut ne pas regarder trop près ce qui se passe...\n",
    "#training_data.set_index('DATE')\n",
    "#training_data.interpolate(method='index',inplace=True)\n",
    "\n",
    "#Assign a number to the day of the week\n",
    "day_to_num_dict = {j:i for i,j in enumerate(['Lundi','Mardi','Mercredi','Jeudi','Vendredi','Samedi','Dimanche'])}\n",
    "\n",
    "training_data['TIME'] = training_data.DATE.map(get_time)\n",
    "training_data['MONTH'] = training_data.DATE.map(get_month)\n",
    "training_data['TSE'] = training_data.DATE.map(get_tse)\n",
    "training_data['WEEK_DAY'] = training_data.DAY_WE_DS.map(day_to_num_dict)\n",
    "training_data['NIGHT'] = (training_data.TPER_TEAM == \"Nuit\") * 1\n",
    "\n",
    "# Remove obsolete columns\n",
    "training_data = training_data[[col for col in training_data.columns if not col in ['DATE','DAY_WE_DS','TPER_TEAM']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert the different ASS_ASSIGNMENTs to booleans\n",
    "for value in submission.ASS_ASSIGNMENT.unique():\n",
    "    training_data[\"ASS_ASSIGNMENT_\"+value] = (training_data.ASS_ASSIGNMENT == value) * 1\n",
    "    \n",
    "# Remove obsolete column\n",
    "training_data = training_data[[col for col in training_data.columns if not col == 'ASS_ASSIGNMENT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View main statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  A simple predictor\n",
    "\n",
    "Lets try building a tree-based boosting predictor with very few attributes just to see how it goes.\n",
    "This predictor will only predict the number of calls received during a given time stamp (e.g. in a 30 minutes slot) and day of week.\n",
    "\n",
    "Note that the date is not relevant for regression, but we can extract some relevant information from it: day of the week, time slot, and if it is a week-end or not.\n",
    "\n",
    "Also, for some reason the data for a given ASS_ASSIGNMENT and DATE is sometimes split, so we have to aggregate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_cols = ['CSPL_RECEIVED_CALLS']\n",
    "input_cols = [col for col in training_data.columns if not col in output_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now create the gradient boosting regressor\n",
    "\n",
    "est = GradientBoostingRegressor(n_estimators=60,learning_rate=0.7,\n",
    "                               max_depth=10\n",
    "                               )\n",
    "\n",
    "\n",
    "est.fit(training_data[input_cols],training_data[output_cols].values.ravel())\n",
    "best_est=est\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = submission.copy()\n",
    "\n",
    "#Deal with NAs\n",
    "test_data.set_index('DATE')\n",
    "test_data.interpolate(method='index',inplace=True)\n",
    "\n",
    "\n",
    "def get_weekday(date):\n",
    "    return dt.datetime.strptime(date,'%Y-%m-%d %H:%M:%S.000').weekday()\n",
    "\n",
    "test_data['TIME'] = test_data.DATE.map(get_time)\n",
    "test_data['MONTH'] = test_data.DATE.map(get_month)\n",
    "test_data['TSE'] = test_data.DATE.map(get_tse)\n",
    "test_data['WEEK_DAY'] = test_data.DATE.map(get_weekday)\n",
    "test_data['NIGHT'] = (np.logical_or(test_data.TIME >= (23*3600 + 30*60),\n",
    "                                    test_data.TIME <  (7*3600  + 30*60))) * 1\n",
    "test_data['WEEK_END'] = test_data.WEEK_DAY.isin([5, 6]) * 1\n",
    "\n",
    "# Convert the different ASS_ASSIGNMENTs to booleans\n",
    "for value in submission.ASS_ASSIGNMENT.unique():\n",
    "    test_data[\"ASS_ASSIGNMENT_\"+value] = (test_data.ASS_ASSIGNMENT == value) * 1\n",
    "\n",
    "test_data = test_data[input_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission.prediction = best_est.predict(test_data)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#no negative number of call\n",
    "submission['prediction'] = submission['prediction'].clip(0,None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.to_csv(\"data/output.txt\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
