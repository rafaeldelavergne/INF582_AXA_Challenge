{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF582 AXA Challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load main librairies\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import datetime as dt\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn import __version__\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "submission = pd.read_csv(\"data/submission.txt\", sep='\\t')\n",
    "training_data = pd.read_csv(\"data/train_2011_2012.csv\", sep=';', nrows=10000,\n",
    "                            na_values=['A Définir', 'A DEFINIR', '9999-12-31 00:00:00.000'],\n",
    "                            usecols=['DATE','WEEK_END','DAY_WE_DS','TPER_TEAM','ASS_ASSIGNMENT','CSPL_RECEIVED_CALLS']\n",
    "                            )\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#list of departements with more than 1 million inhabitants\n",
    "big_dept = ['59','75''13','92','93','33','62','78','77','94','44','31','76','91','38','95','67','34','06','83','57','35']\n",
    "\n",
    "\n",
    "iter_csv = pd.read_csv(\"data/meteo_2012.csv\", iterator=True, chunksize=1000,\n",
    "                           #nrows=50000,\n",
    "                           header=None,\n",
    "                           usecols=[0,1,3,6]\n",
    "                          )\n",
    "meteo2012 = pd.concat([chunk[chunk[1].isin(big_dept)] for chunk in iter_csv])\n",
    "\n",
    "\n",
    "meteo2012.rename(columns={0: 'DATE', 1: 'DEPT',3:'TEMP',6:'RAIN'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "iter_csv = pd.read_csv(\"data/meteo_2011.csv\", iterator=True, chunksize=1000,\n",
    "                           #nrows=50000,\n",
    "                           header=None,\n",
    "                           usecols=[0,1,3,6]\n",
    "                          )\n",
    "meteo2011 = pd.concat([chunk[chunk[1].isin(big_dept)] for chunk in iter_csv])\n",
    "\n",
    "\n",
    "meteo2011.rename(columns={0: 'DATE', 1: 'DEPT',3:'TEMP',6:'RAIN'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "frames=[meteo2012,meteo2011]\n",
    "\n",
    "meteo=pd.concat(frames)\n",
    "\n",
    "def format_date(date):\n",
    "    return dt.datetime.strptime(date, '%Y-%m-%d %H:%M').strftime('%Y-%m-%d %H:%M:%S.000')\n",
    "\n",
    "meteo['DATE'] = meteo.DATE.map(format_date)\n",
    "\n",
    "#Format meteo\n",
    "for dept in sorted(meteo.DEPT.unique()):\n",
    "    index = (meteo.DEPT == dept)\n",
    "    meteo[\"{}_TEMP\".format(dept)] = meteo.TEMP * index\n",
    "    meteo[\"{}_RAIN\".format(dept)] = meteo.RAIN * index\n",
    "\n",
    "meteo.drop([\"DEPT\", \"RAIN\", \"TEMP\"], axis=1, inplace=True)\n",
    "meteo = meteo.groupby(\"DATE\").max().reset_index()\n",
    "\n",
    "meteo.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "meteo.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove non usefull rows\n",
    "training_data = training_data[training_data.ASS_ASSIGNMENT.isin(submission.ASS_ASSIGNMENT.unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Aggregate the calls\n",
    "training_data = training_data.groupby([col for col in training_data.columns if not col == 'CSPL_RECEIVED_CALLS']).sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extract the time slot from date\n",
    "def get_time(date):\n",
    "    time = dt.datetime.strptime(date,'%Y-%m-%d %H:%M:%S.000').time()\n",
    "    return time.hour * 3600 + time.minute * 60 + time.second\n",
    "\n",
    "def get_month(date):\n",
    "    month = dt.datetime.strptime(date,'%Y-%m-%d %H:%M:%S.000').month\n",
    "    return month\n",
    "\n",
    "#Join weather\n",
    "training_data = pd.merge(training_data, meteo, how='left', on=['DATE'])\n",
    "\n",
    "#Deal with NAs. Would be better to replace with average\n",
    "#training_data.fillna(0,inplace = True)\n",
    "\n",
    "#Ca a l'air de fonctionner mais mieux vaut ne pas regarder trop près ce qui se passe...\n",
    "training_data.set_index('DATE')\n",
    "training_data.interpolate(method='index',inplace=True)\n",
    "\n",
    "#Assign a number to the day of the week\n",
    "day_to_num_dict = {j:i for i,j in enumerate(['Lundi','Mardi','Mercredi','Jeudi','Vendredi','Samedi','Dimanche'])}\n",
    "\n",
    "training_data['TIME'] = training_data.DATE.map(get_time)\n",
    "training_data['MONTH'] = training_data.DATE.map(get_month)\n",
    "training_data['WEEK_DAY'] = training_data.DAY_WE_DS.map(day_to_num_dict)\n",
    "training_data['NIGHT'] = (training_data.TPER_TEAM == \"Nuit\") * 1\n",
    "\n",
    "# Remove obsolete columns\n",
    "training_data = training_data[[col for col in training_data.columns if not col in ['DATE','DAY_WE_DS','TPER_TEAM']]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Convert the different ASS_ASSIGNMENTs to booleans\n",
    "for value in submission.ASS_ASSIGNMENT.unique():\n",
    "    training_data[\"ASS_ASSIGNMENT_\"+value] = (training_data.ASS_ASSIGNMENT == value) * 1\n",
    "    \n",
    "# Remove obsolete column\n",
    "training_data = training_data[[col for col in training_data.columns if not col == 'ASS_ASSIGNMENT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View main statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  A simple predictor\n",
    "\n",
    "Lets try building a tree-based boosting predictor with very few attributes just to see how it goes.\n",
    "This predictor will only predict the number of calls received during a given time stamp (e.g. in a 30 minutes slot) and day of week.\n",
    "\n",
    "Note that the date is not relevant for regression, but we can extract some relevant information from it: day of the week, time slot, and if it is a week-end or not.\n",
    "\n",
    "Also, for some reason the data for a given ASS_ASSIGNMENT and DATE is sometimes split, so we have to aggregate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_cols = ['CSPL_RECEIVED_CALLS']\n",
    "input_cols = [col for col in training_data.columns if not col in output_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Now create the gradient boosting regressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(training_data[input_cols],  training_data[output_cols].values.ravel())\n",
    "\n",
    "est = GradientBoostingRegressor()\n",
    "\n",
    "tuned_parameters = {'loss' : ['ls'],'n_estimators':[50,80],'learning_rate': [0.5], 'subsample': [1.0],\n",
    "                  'min_samples_split':[1,3],'min_samples_leaf':[1,3],\n",
    "                    'max_depth':[5,8,15,20,25],'max_features':['auto']\n",
    "                 }\n",
    "                     \n",
    "\n",
    "clf = RandomizedSearchCV(est, tuned_parameters, cv=5,n_jobs=-1,n_iter=20,verbose=1)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "est_temoin=GradientBoostingRegressor(n_estimators=100,max_depth=25)\n",
    "est_temoin.fit(X_train,y_train)\n",
    "\n",
    "print(clf.best_params_)\n",
    "best_est=clf.best_estimator_\n",
    "\n",
    "#Plot CV error (this is squared loss, which will be used to evaluate our performance in the leaderboard)\n",
    "\n",
    "#Sur 10.000 lignes best_estimator est souvent moins bon que le temoin.. Par contre la différence est nette\n",
    "# quand on utilise toutes les données.\n",
    "#The higher the score the better.\n",
    "print(\"Best estimator : %.4f\" %best_est.score(X_test,y_test))\n",
    "print(\"Temoin : %.4f\" %est_temoin.score(X_test,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction and submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_data = submission.copy()\n",
    "\n",
    "#Join weather\n",
    "test_data = pd.merge(test_data, meteo, how='left', on=['DATE'])\n",
    "\n",
    "#Deal with NAs\n",
    "test_data.set_index('DATE')\n",
    "test_data.interpolate(method='index',inplace=True)\n",
    "\n",
    "\n",
    "def get_weekday(date):\n",
    "    return dt.datetime.strptime(date,'%Y-%m-%d %H:%M:%S.000').weekday()\n",
    "\n",
    "test_data['TIME'] = test_data.DATE.map(get_time)\n",
    "test_data['MONTH'] = test_data.DATE.map(get_month)\n",
    "test_data['WEEK_DAY'] = test_data.DATE.map(get_weekday)\n",
    "test_data['NIGHT'] = (np.logical_or(test_data.TIME >= (23*3600 + 30*60),\n",
    "                                    test_data.TIME <  (7*3600  + 30*60))) * 1\n",
    "test_data['WEEK_END'] = test_data.WEEK_DAY.isin([5, 6]) * 1\n",
    "\n",
    "# Convert the different ASS_ASSIGNMENTs to booleans\n",
    "for value in submission.ASS_ASSIGNMENT.unique():\n",
    "    test_data[\"ASS_ASSIGNMENT_\"+value] = (test_data.ASS_ASSIGNMENT == value) * 1\n",
    "\n",
    "test_data = test_data[input_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission.prediction = est_temoin.predict(test_data)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write prediction to csv\n",
    "submission.to_csv(\"data/output.txt\", sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
